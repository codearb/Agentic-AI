{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "while True:\n",
    "    project_name = input(\"Enter the Src Folder Name: \")\n",
    "    if project_name != '':\n",
    "        break\n",
    "\n",
    "\n",
    "list_of_files = [\n",
    "f\"src/__init__.py\",\n",
    "f\"src/__pycache__\",\n",
    "f\"src/{project_name}/__pycache__\",\n",
    "f\"src/{project_name}/__init__.py\",\n",
    "\n",
    "\n",
    "f\"src/{project_name}/graph/__pycache__\",\n",
    "f\"src/{project_name}/graph/__init__.py\",\n",
    "\\\n",
    "f\"src/{project_name}/LLMS/__pycache__\",\n",
    "f\"src/{project_name}/LLMS/__init__.py\",\n",
    "\n",
    "f\"src/{project_name}/nodes/__pycache__\",\n",
    "f\"src/{project_name}/nodes/__init__.py\",\n",
    "\n",
    "f\"src/{project_name}/state/__pycache__\",\n",
    "f\"src/{project_name}/state/__init__.py\",\n",
    "\n",
    "f\"src/{project_name}/tools/__init__.py\",\n",
    "\n",
    "f\"src/{project_name}/user_interface/__pycache__\",\n",
    "f\"src/{project_name}/user_interface/__init__.py\",\n",
    "\n",
    "f\"src/{project_name}/user_interface/streamlitui/__pycache__\",\n",
    "\n",
    "f\"src/{project_name}/vector_store/__init__.py\",\n",
    "]\n",
    "\n",
    "for filepath in list_of_files:\n",
    "    filepath=Path(filepath)\n",
    "    filedir, filename=os.path.split(filepath)\n",
    "    \n",
    "    if filedir != \"\":\n",
    "        os.makedirs(filedir,exist_ok=True)\n",
    "    if not os.path.exists(filepath):\n",
    "        with open(filepath,\"w\") as f:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src/__init__.py',\n",
       " 'src/__pycache__',\n",
       " 'src/Langgraph_Agentic_AI/__pycache__',\n",
       " 'src/Langgraph_Agentic_AI/__init__.py',\n",
       " 'src/Langgraph_Agentic_AI/graph/__pycache__',\n",
       " 'src/Langgraph_Agentic_AI/graph/__init__.py',\n",
       " 'src/Langgraph_Agentic_AI/LLMS/__pycache__',\n",
       " 'src/Langgraph_Agentic_AI/LLMS/__init__.py',\n",
       " 'src/Langgraph_Agentic_AI/nodes/__pycache__',\n",
       " 'src/Langgraph_Agentic_AI/nodes/__init__.py',\n",
       " 'src/Langgraph_Agentic_AI/state/__pycache__',\n",
       " 'src/Langgraph_Agentic_AI/state/__init__.py',\n",
       " 'src/Langgraph_Agentic_AI/tools/__init__.py',\n",
       " 'src/Langgraph_Agentic_AI/user_interface/__pycache__',\n",
       " 'src/Langgraph_Agentic_AI/user_interface/__init__.py',\n",
       " 'src/Langgraph_Agentic_AI/user_interface/streamlitui/__pycache__',\n",
       " 'src/Langgraph_Agentic_AI/vector_store/__init__.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Langgraph_Agentic_AI/user_interface/uiconfigfile.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile  src/Langgraph_Agentic_AI/user_interface/uiconfigfile.ini\n",
    "[DEFAULT]\n",
    "PAGE_TITLE = LangGraph: Build Stateful Agentic AI graph\n",
    "LLM_OPTIONS = Groq\n",
    "USECASE_OPTIONS = Basic Chatbot\n",
    "GROQ_MODEL_OPTIONS = qwen-2.5-32b, mixtral-8x7b-32768, llama3-8b-8192, llama3-70b-8192, gemma-7b-i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Langgraph_Agentic_AI/user_interface/uiconfigfile.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  src/Langgraph_Agentic_AI/user_interface/uiconfigfile.py\n",
    "from configparser import ConfigParser\n",
    "\n",
    "class Config:\n",
    "    def __init__(self,config_file=\"./src/Langgraph_Agentic_AI/user_interface/uiconfigfile.ini\"):\n",
    "        self.config=ConfigParser()\n",
    "        self.config.read(config_file)\n",
    "\n",
    "    def get_llm_options(self):\n",
    "        return self.config[\"DEFAULT\"].get(\"LLM_OPTIONS\").split(\", \")\n",
    "    \n",
    "    def get_usecase_options(self):\n",
    "        return self.config[\"DEFAULT\"].get(\"USECASE_OPTIONS\").split(\", \")\n",
    "\n",
    "    def get_groq_model_options(self):\n",
    "        return self.config[\"DEFAULT\"].get(\"GROQ_MODEL_OPTIONS\").split(\", \")\n",
    "\n",
    "    def get_page_title(self):\n",
    "        return self.config[\"DEFAULT\"].get(\"PAGE_TITLE\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Langgraph_Agentic_AI/state/state.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  src/Langgraph_Agentic_AI/state/state.py\n",
    "from typing import Annotated, Literal, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the structure of the state used in the graph.\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Langgraph_Agentic_AI/LLMS/llm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  src/Langgraph_Agentic_AI/LLMS/llm.py\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "class GroqLLM:\n",
    "    def __init__(self,user_controls_input):\n",
    "        self.user_controls_input=user_controls_input\n",
    "\n",
    "    def get_llm_model(self):\n",
    "        try:\n",
    "            groq_api_key=self.user_controls_input['GROQ_API_KEY']\n",
    "            selected_groq_model=self.user_controls_input['selected_groq_model']\n",
    "            if groq_api_key=='' and os.environ[\"GROQ_API_KEY\"] =='':\n",
    "                st.error(\"Please Enter the Groq API KEY\")\n",
    "\n",
    "            llm = ChatGroq(api_key =groq_api_key, model=selected_groq_model)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error Occurred with Exception : {e}\")\n",
    "        return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Langgraph_Agentic_AI/nodes/basic_chatbot_node.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  src/Langgraph_Agentic_AI/nodes/basic_chatbot_node.py\n",
    "from src.Langgraph_Agentic_AI.state.state import State\n",
    "\n",
    "class BasicChatbotNode:\n",
    "    \"\"\"\n",
    "    Basic chatbot logic implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self,model):\n",
    "        self.llm = model\n",
    "\n",
    "    def process(self, state: State) -> dict:\n",
    "        \"\"\"\n",
    "        Processes the input state and generates a chatbot response.\n",
    "        \"\"\"\n",
    "        return {\"messages\":self.llm.invoke(state['messages'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Langgraph_Agentic_AI/graph/graph_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/Langgraph_Agentic_AI/graph/graph_builder.py\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from src.Langgraph_Agentic_AI.state.state import State\n",
    "from src.Langgraph_Agentic_AI.nodes.basic_chatbot_node import BasicChatbotNode\n",
    "\n",
    "class GraphBuilder:\n",
    "\n",
    "    def __init__(self,model):\n",
    "        self.llm=model\n",
    "        self.graph_builder=StateGraph(State)\n",
    "\n",
    "    def basic_chatbot_build_graph(self):\n",
    "        \"\"\"\n",
    "        Builds a basic chatbot graph using LangGraph.\n",
    "        This method initializes a chatbot node using the `BasicChatbotNode` class \n",
    "        and integrates it into the graph. The chatbot node is set as both the \n",
    "        entry and exit point of the graph.\n",
    "        \"\"\"\n",
    "        self.basic_chatbot_node=BasicChatbotNode(self.llm)\n",
    "        self.graph_builder.add_node(\"chatbot\",self.basic_chatbot_node.process)\n",
    "        self.graph_builder.add_edge(START,\"chatbot\")\n",
    "        self.graph_builder.add_edge(\"chatbot\",END)\n",
    "\n",
    "    def setup_graph(self, usecase: str):\n",
    "        \"\"\"\n",
    "        Sets up the graph for the selected use case.\n",
    "        \"\"\"\n",
    "        if usecase == \"Basic Chatbot\":\n",
    "            self.basic_chatbot_build_graph()\n",
    "        return self.graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Langgraph_Agentic_AI/user_interface/streamlitui/loadui.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/Langgraph_Agentic_AI/user_interface/streamlitui/loadui.py\n",
    "import streamlit as st\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from src.Langgraph_Agentic_AI.user_interface.uiconfigfile import Config\n",
    "\n",
    "\n",
    "class LoadStreamlitUI:\n",
    "    def __init__(self):\n",
    "        self.config =  Config() # config\n",
    "        self.user_controls = {}\n",
    "\n",
    "    def initialize_session(self):\n",
    "        return {\n",
    "        \"current_step\": \"requirements\",\n",
    "        \"requirements\": \"\",\n",
    "        \"user_stories\": \"\",\n",
    "        \"po_feedback\": \"\",\n",
    "        \"generated_code\": \"\",\n",
    "        \"review_feedback\": \"\",\n",
    "        \"decision\": None\n",
    "    }\n",
    "  \n",
    "\n",
    "\n",
    "    def load_streamlit_ui(self):\n",
    "        st.set_page_config(page_title= self.config.get_page_title(), layout=\"wide\")\n",
    "        st.header(self.config.get_page_title())\n",
    "        st.session_state.timeframe = ''\n",
    "        st.session_state.IsFetchButtonClicked = False\n",
    "        st.session_state.IsSDLC = False\n",
    "        \n",
    "        \n",
    "\n",
    "        with st.sidebar:\n",
    "            # Get options from config\n",
    "            llm_options = self.config.get_llm_options()\n",
    "            usecase_options = self.config.get_usecase_options()\n",
    "\n",
    "            # LLM selection\n",
    "            self.user_controls[\"selected_llm\"] = st.selectbox(\"Select LLM\", llm_options)\n",
    "\n",
    "            if self.user_controls[\"selected_llm\"] == 'Groq':\n",
    "                # Model selection\n",
    "                model_options = self.config.get_groq_model_options()\n",
    "                self.user_controls[\"selected_groq_model\"] = st.selectbox(\"Select Model\", model_options)\n",
    "                # API key input\n",
    "                self.user_controls[\"GROQ_API_KEY\"] = st.session_state[\"GROQ_API_KEY\"] = st.text_input(\"API Key\",\n",
    "                                                                                                      type=\"password\")\n",
    "                # Validate API key\n",
    "                if not self.user_controls[\"GROQ_API_KEY\"]:\n",
    "                    st.warning(\"⚠️ Please enter your GROQ API key to proceed. Don't have? refer : https://console.groq.com/keys \")\n",
    "                   \n",
    "            \n",
    "            # Use case selection\n",
    "            self.user_controls[\"selected_usecase\"] = st.selectbox(\"Select Usecases\", usecase_options)\n",
    "            \n",
    "            if \"state\" not in st.session_state:\n",
    "                st.session_state.state = self.initialize_session()  \n",
    "        \n",
    "        return self.user_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Langgraph_Agentic_AI/user_interface/streamlitui/display_result.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/Langgraph_Agentic_AI/user_interface/streamlitui/display_result.py\n",
    "import streamlit as st\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "import json\n",
    "\n",
    "class DisplayResultStreamlit:\n",
    "    def __init__(self,usecase,graph,user_message):\n",
    "        self.usecase= usecase\n",
    "        self.graph = graph\n",
    "        self.user_message = user_message\n",
    "\n",
    "    def display_result_on_ui(self):\n",
    "        usecase= self.usecase\n",
    "        graph = self.graph\n",
    "        user_message = self.user_message\n",
    "        if usecase ==\"Basic Chatbot\":\n",
    "                for event in graph.stream({'messages':(\"user\",user_message)}):\n",
    "                    print(event.values())\n",
    "                    for value in event.values():\n",
    "                        print(value['messages'])\n",
    "                        with st.chat_message(\"user\"):\n",
    "                            st.write(user_message)\n",
    "                        with st.chat_message(\"assistant\"):\n",
    "                            st.write(value[\"messages\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Langgraph_Agentic_AI/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/Langgraph_Agentic_AI/main.py\n",
    "import streamlit as st\n",
    "import json\n",
    "from src.Langgraph_Agentic_AI.user_interface.streamlitui.loadui import LoadStreamlitUI\n",
    "from src.Langgraph_Agentic_AI.user_interface.streamlitui.display_result import DisplayResultStreamlit\n",
    "\n",
    "from src.Langgraph_Agentic_AI.LLMS.llm import GroqLLM\n",
    "from src.Langgraph_Agentic_AI.graph.graph_builder import GraphBuilder\n",
    "\n",
    "# MAIN Function START\n",
    "def load_langgraph_agenticai_app():\n",
    "    \"\"\"\n",
    "    Loads and runs the LangGraph AgenticAI application with Streamlit UI.\n",
    "    This function initializes the UI, handles user input, configures the LLM model,\n",
    "    sets up the graph based on the selected use case, and displays the output while \n",
    "    implementing exception handling for robustness.\n",
    "    \"\"\"\n",
    "   \n",
    "    # Load UI\n",
    "    ui = LoadStreamlitUI()\n",
    "    user_input = ui.load_streamlit_ui()\n",
    "\n",
    "    if not user_input:\n",
    "        st.error(\"Error: Failed to load user input from the UI.\")\n",
    "        return\n",
    "\n",
    "    # Text input for user message\n",
    "    if st.session_state.IsFetchButtonClicked:\n",
    "        user_message = st.session_state.timeframe \n",
    "    else :\n",
    "        user_message = st.chat_input(\"Enter your message:\")\n",
    "\n",
    "    if user_message:\n",
    "            try:\n",
    "                # Configure LLM\n",
    "                obj_llm_config = GroqLLM(user_controls_input=user_input)\n",
    "                model = obj_llm_config.get_llm_model()\n",
    "                \n",
    "                if not model:\n",
    "                    st.error(\"Error: LLM model could not be initialized.\")\n",
    "                    return\n",
    "\n",
    "                # Initialize and set up the graph based on use case\n",
    "                usecase = user_input.get('selected_usecase')\n",
    "                if not usecase:\n",
    "                    st.error(\"Error: No use case selected.\")\n",
    "                    return\n",
    "                \n",
    "\n",
    "                ### Graph Builder\n",
    "                graph_builder=GraphBuilder(model)\n",
    "                try:\n",
    "                    graph = graph_builder.setup_graph(usecase)\n",
    "                    DisplayResultStreamlit(usecase,graph,user_message).display_result_on_ui()\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Error: Graph setup failed - {e}\")\n",
    "                    return\n",
    "                \n",
    "\n",
    "            except Exception as e:\n",
    "                 raise ValueError(f\"Error Occurred with Exception : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "from src.Langgraph_Agentic_AI.main import load_langgraph_agenticai_app\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    load_langgraph_agenticai_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
